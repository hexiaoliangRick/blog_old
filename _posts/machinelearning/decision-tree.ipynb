{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitsoftwarevirtualenvc111ffd064454e9fafc15e1bfc187713",
   "display_name": "Python 3.7.3 64-bit ('SoftWare': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def calEntropy(inDataFrame):\n",
    "    #约定，通常把最后一列作为标签\n",
    "    labelSeries=inDataFrame.iloc[:,-1]\n",
    "    freqSum= labelSeries.value_counts()\n",
    "    #记录的总条数\n",
    "    sumRecord=inDataFrame.shape[0]\n",
    "    entropy=-(freqSum/sumRecord)*((freqSum/sumRecord).apply(math.log2))\n",
    "    sumentropy=entropy.sum()\n",
    "    return sumentropy\n",
    "\n",
    "def createDataSet():\n",
    "    inputDic={'no surfacing':[1,1,1,0,0],\n",
    "    'flippers':[1,1,0,1,1],\n",
    "    'fish':['yes','yes','yes','no','no']}\n",
    "    dataSet= pd.DataFrame(inputDic)\n",
    "    return dataSet\n",
    "\n",
    "def bestSplit(dataset):\n",
    "    bestColIndex=-1\n",
    "    #计算原始数据集合的信息熵\n",
    "    setEntropy=calEntropy(dataset)\n",
    "    #循环各个列，分别计算各个列的修正信息熵、信息增益\n",
    "    colnum=dataset.shape[1]\n",
    "    sumrecord=dataset.shape[0]\n",
    "    maxgain=0\n",
    "    for colindex in range(0,colnum):\n",
    "        #计算修正信息熵\n",
    "        colset=dataset.iloc[:,colindex]\n",
    "        colValueFreq=colset.value_counts()\n",
    "        colEntropy=0\n",
    "        for colvalueindex in colValueFreq.index:\n",
    "            colValueSum=colValueFreq[colvalueindex]\n",
    "            #取出等于该属性值的数据\n",
    "            boolIndex=colset==colvalueindex\n",
    "            valueSet=dataset[boolIndex]\n",
    "            valueEntropy=calEntropy(valueSet)\n",
    "            correctEntropy=(colValueSum/sumrecord)*valueEntropy\n",
    "            colEntropy+=correctEntropy\n",
    "        #计算列的信息增益\n",
    "        colgain=setEntropy-colEntropy\n",
    "        #比较信息增益，挑选信息增益最大的特征，返回特征列索引\n",
    "        if(colgain>maxgain):\n",
    "            maxgain=colgain\n",
    "            bestColIndex=colindex\n",
    "    return bestColIndex\n",
    "def splitDataSet(dataset,colindex,colvalue):\n",
    "    filter=dataset.iloc[:,colindex]==colvalue\n",
    "    selected= dataset.loc[filter,:]\n",
    "    return selected\n",
    "\n",
    "\"\"\"\n",
    "递归分类\n",
    "\"\"\"\n",
    "def classify(dataset):\n",
    "    #如果没有特征可供选择，或者所有的数据都是同一类别，可以不用划分\n",
    "    featurelist=list(dataset.columns)\n",
    "    classlist=dataset.iloc[:,-1].value_counts()\n",
    "    if classlist[0]==dataset.shape[0] or dataset.shape[1]==1:\n",
    "        return classlist.index[0]\n",
    "    #选择列标签\n",
    "    colindex=bestSplit(dataset)\n",
    "    collabel=featurelist[colindex]\n",
    "    #决策树\n",
    "    mytree={collabel:{}}\n",
    "    del featurelist[colindex]\n",
    "    valuelist=set(dataset.iloc[:,colindex])\n",
    "    for value in valuelist:\n",
    "        mytree[collabel][value]=classify(splitDataSet(dataset,colindex,value))\n",
    "    return mytree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 决策树的存储\n",
    " 使用 numpy 的npy文件进行存储，然后再调用load函数进行加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\"\"\"\n",
    " 分类单条记录的类别\n",
    "\"\"\"\n",
    "def classifyrecord(mytree,labels,record):\n",
    "    firstkey= next(iter(mytree))\n",
    "    valuedic= mytree[firstkey]\n",
    "    #判断特征\n",
    "    featureindex=labels.index(firstkey)\n",
    "    featurevalue=record[featureindex]\n",
    "    for key in valuedic.keys():\n",
    "        if featurevalue==key:\n",
    "            if type(valuedic[key])==dict:\n",
    "                classlabel=classifyrecord(valuedic[key],labels,record)\n",
    "            else:\n",
    "                classlabel=valuedic[key]\n",
    "    return classlabel\n",
    "\n",
    "\n",
    "    \n",
    "def acc_classify(train,test):\n",
    "    #创建决策树\n",
    "    decisiontree=classify(train)\n",
    "    columnlabels=list(test.columns)\n",
    "    #分类数据\n",
    "    classifylabels=[]\n",
    "    for rowindex in range(0,test.shape[0]):\n",
    "        record=test.iloc[rowindex,:-1]\n",
    "        label= classifyrecord(decisiontree,columnlabels,record)\n",
    "        classifylabels.append(label)\n",
    "    #计算准确率\n",
    "    test['predict']=classifylabels\n",
    "    accuracy=(test.iloc[:,-1]==test.iloc[:,-2]).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=createDataSet()\n",
    "train=dataset\n",
    "test=dataset.iloc[:3,:]\n",
    "acc_classify(train,test)"
   ]
  }
 ]
}

# Spark学习记录
--------
##Docker搭建Hadoop3.0完全分布式集群
####参考文档
1.博客文章：https://www.cnblogs.com/onetwo/p/6419925.html    
2.官方文档：https://hadoop.apache.org/docs/r0.23.11/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
####实际操作
##### 单机集群搭建以及运行wordcount例子
1. 参考指导：https://hadoop.apache.org/docs/r3.1.3/hadoop-project-dist/hadoop-common/SingleCluster.html
   如果网页在google中显示有问题，可以选择用ie浏览器试试。   
2. step by step 的进行配置。
3. 操作过程中遇到的问题总结
 - 提交任务之后，连接不上Resource Manager ，报错
 ```cluster-master:18040 failed on connection exception: java.net.ConnectException: Connection refused; For                                                                                                                         more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationClientProtocolPBCli                                                                                                                        entImpl.getNewApplication over null after 1 failover attempts. ```

 ![hadoop3.0-rs连接不上报错](../img/gis/spark/hadoop3.0-rs连接不上报错.png)
 ---
 **原因**  
 在启动集群的时候只调用了start-dfs.sh脚本，没有调用start-all.sh脚本，导致集群只启动了hdfs的服务，没有启动rs相关的服务。
 - Hadoop集群安全模式下，提交任务失败 ```org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/root/grep-temp-1689422376. Name node is in safe mode.```
 ![hadoop-3.0集群安全模式](../img/gis/spark/hadoop-3.0集群安全模式.png)
 **原因**  
 安全模式是集群自我保护的一种机制，在安全模式下，不允许对文件进行删除操作。在NameNode主节点启动时，HDFS首先进入安全模式，DataNode在启动的时候会向namenode汇报可用的block等状态，当整个系统达到安全标准时，HDFS自动离开安全模式。
 在我的操作中，集群刚启动，我就开始提交任务，这时候，集群必须删除上一次任务执行的记录信息，但是处在安全模式下，所以任务运行失败。
 **如何退出安全模式，如何查看当前是否处于安全模式**
 https://blog.csdn.net/bingduanlbd/article/details/51900512
 - mapred-site.xml文件中没有配置，map、reduce运行的环境变量，导致任务运行失败。`NFO mapreduce.Job: Job job_1575113633802_0002 failed with state FAILED due to: Application application_1575113633802_0002 failed 2 times due to AM Container for appattempt_1575113633802_0002_000002 exited with  exitCode: 1
                                                      Failing this attempt.Diagnostics: [2019-11-30 11:40:06.901]Exception from container-launch.
                                                      Container id: container_1575113633802_0002_02_000001
                                                      Exit code: 1
                                                      [2019-11-30 11:40:06.907]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
                                                      Last 4096 bytes of prelaunch.err :
                                                      Last 4096 bytes of stderr :
                                                      Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster`
 ![hadoop-3.0Mapreduce环境变量](../img/gis/spark/hadoop-3.0Mapreduce环境变量.png)
 **原因**   
 https://mathsigit.github.io/blog_page/2017/11/16/hole-of-submitting-mr-of-hadoop300RC0/
 **In Hadoop 3, YARN containers do not inherit the NodeManagers’ environment variables. Therefore, if you want to inherit NodeManager’s environment variables (e.g. HADOOP_MAPRED_HOME), you need to set additional parameters (e.g. mapreduce.admin.user.env and yarn.app.mapreduce.am.env).**
 3.0集群，不支持环境变量的继承，所以我们需要在配置文件中添加配置项。
 - 调用start-all.sh脚本之后，集群只启动namenode、secondnamenode服务，没有datanode服务运行。
 **原因**
 数据不一致，删除集群环境下，dfs数据存储的位置。
 集群的启动、关闭要通过脚本执行，不能强制杀死进程。
 
####知识总结